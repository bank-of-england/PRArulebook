---
title: "Introduction to PRArulebook package"
author: "Eryk Walczak"
date: "`r Sys.Date()`" 
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction-to-PRA-rulebook}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(PRArulebook)
```

Get the structure:

```{r}
sectors <- scrape_sector_structure("http://www.prarulebook.co.uk/rulebook/Home/Handbook/22-03-2006")
parts <- scrape_part_structure(sectors)
```

This is quite large so only small parts were scraped.

See what was scraped:

```{r, warning = FALSE, message = FALSE}
library(dplyr)

dplyr::glimpse(parts)
```


Visualise the structure:

```{r, warning = FALSE, message = FALSE}
library(collapsibleTree)

Handbook <- parts

collapsibleTree(
  Handbook,
  hierarchy = c("sector_name", "part_name"),
  width = 800,
  height = 1100,
  zoomable = FALSE,
  collapsed = FALSE
)
```

Obtaining rule-level content (including rule URLs) is a slow process and might not be needed. 

```{r, eval = FALSE}
rules_df <-
  scrape_rule_structure(chapters_df,
                        date = "16-11-2007")
```

This will generate a data frame with rule-level structure. The next step (if you require the lowest level of the data) is obtaining the rule IDs and text. This is *very slow* as individual rule IDs are not so easy to extract and the scraper needs to visit every single rule URL.

```{r, eval = FALSE}
rules_df_id <- list()

for (i in 1:nrow(rules_df)) {
  print(i)
  rules_df_id[[i]] <-
    scrape_rule_id(rules_df$rule_url[i],
                   rules_df$rule_number_sel[i],
                   rules_df$rule_text_sel[i])
}

rules_df_id_df <- dplyr::bind_rows(rules_df_id)
```

## Faster scraping

Future and furrr packages were tested to speed up the process of scraping but this method often resulted in errors. Instead, purrr was used in this package for sending requests.

If you want to experiment with furrr then here is a code example that was previously used in `scrape_chapter_structure.R`:

```{r, eval = FALSE}
# scrape part-level data
df <-
  get_structure("01-01-2010",
                layer = "part")

# start multicore processing
library(future)
plan(multiprocess)

# get all chapters and append to a data frame
chapters <-
  furrr::future_map_dfr(df$part_url,
                scrape_menu, selector = ".Chapter a",
                .progress = TRUE)
```

